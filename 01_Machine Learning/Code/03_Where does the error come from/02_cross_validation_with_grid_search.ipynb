{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use sklearn bulit-in grid-search-cv to tune hyper-parameters. We can't use this to choose models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc = {\"axes.titlesize\": 20, \"axes.labelsize\": 15, \"legend.fontsize\": 15, \"lines.linewidth\": 3, \"figure.figsize\": (9, 4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset (classification) and divide into training and testing.\n",
    "X, y = datasets.load_digits(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV    # Only return scores.\n",
    "\n",
    "param_grid_list = [{\"kernel\": [\"rbf\"], \"gamma\": [1e-3, 1e-4],\n",
    "                     \"C\": [1, 10, 100, 1000]},\n",
    "                   {\"kernel\": [\"linear\"], \"C\": [1, 10, 100, 1000]}]\n",
    "\n",
    "# scoring = \"accuracy\"\n",
    "scoring = \"f1_macro\"\n",
    "\n",
    "clf = GridSearchCV(SVC(), param_grid_list, scoring = scoring)\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "cv_score on training set:\n",
      "\n",
      "(0) \t 0.990 (+/-0.011) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "(1) \t 0.967 (+/-0.024) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "(2) \t 0.991 (+/-0.009) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "(3) \t 0.983 (+/-0.018) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "(4) \t 0.991 (+/-0.009) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "(5) \t 0.987 (+/-0.008) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "(6) \t 0.991 (+/-0.009) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "(7) \t 0.987 (+/-0.008) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "(8) \t 0.978 (+/-0.017) for {'C': 1, 'kernel': 'linear'}\n",
      "(9) \t 0.978 (+/-0.017) for {'C': 10, 'kernel': 'linear'}\n",
      "(10) \t 0.978 (+/-0.017) for {'C': 100, 'kernel': 'linear'}\n",
      "(11) \t 0.978 (+/-0.017) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The testing_score are computed on the full testing set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        59\n",
      "     class 1       0.98      1.00      0.99        49\n",
      "     class 2       1.00      1.00      1.00        49\n",
      "     class 3       1.00      1.00      1.00        64\n",
      "     class 4       1.00      1.00      1.00        61\n",
      "     class 5       0.96      0.98      0.97        47\n",
      "     class 6       1.00      1.00      1.00        51\n",
      "     class 7       1.00      0.98      0.99        57\n",
      "     class 8       1.00      0.98      0.99        46\n",
      "     class 9       0.96      0.96      0.96        57\n",
      "\n",
      "    accuracy                           0.99       540\n",
      "   macro avg       0.99      0.99      0.99       540\n",
      "weighted avg       0.99      0.99      0.99       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Best parameters set found on training set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"cv_score on training set:\")\n",
    "print()\n",
    "mean_list = clf.cv_results_[\"mean_test_score\"]\n",
    "std_list = clf.cv_results_[\"std_test_score\"]\n",
    "for i in range(len(mean_list)):\n",
    "    print(\"({index}) \\t {mean:.3f} (+/-{std:.3f}) for {parameters}\" \\\n",
    "          .format(index = i, \\\n",
    "                  mean = mean_list[i], \\\n",
    "                  std = std_list[i] * 2, \\\n",
    "                  parameters = clf.cv_results_[\"params\"][i]))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full training set.\")\n",
    "print(\"The testing_score are computed on the full testing set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred, target_names = [ \"class \" + str(i) for i in range(10) ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
